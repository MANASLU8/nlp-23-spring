{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rg_ReNhJEHLx",
        "outputId": "46a48306-b4c5-47a3-cd19-0b40090d13a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Python 3.9.16\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JVfO-RIE_lI",
        "outputId": "5abee0c4-bc3f-4c0e-d8b1-5503af92bc88"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import regex as re\n",
        "import os\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "assets_url = 'gdrive/My Drive/Colab Notebooks/nlp-2023/assets/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6TIeIZvco9bk"
      },
      "outputs": [],
      "source": [
        "stops = set(stopwords.words('english'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "FTk_1xpzN7JL",
        "outputId": "1a74a714-b6f1-4b74-ff3f-d6195a98a444"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2832572\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "trigrams = []\n",
        "trigram_frequences_dict = dict()\n",
        "word_frequences_dict = dict()\n",
        "S = 0\n",
        "\n",
        "text = ''\n",
        "\n",
        "file_no = 0\n",
        "for address, dirs, files in os.walk(assets_url):\n",
        "  for name in files:\n",
        "    file_no += 1\n",
        "    with open(os.path.join(address, name), mode='r') as annotated_document_file:\n",
        "      for sentence in annotated_document_file.read().split('\\n\\n'):\n",
        "        lemms = []\n",
        "        for annotation in sentence.split('\\n'):\n",
        "          word_stem_lem = annotation.split('\\t')\n",
        "          if len(word_stem_lem) == 3:\n",
        "            lemma = word_stem_lem[2]\n",
        "            # Очистить полученные данные от знаков пунктуации. Можно использовать регулярное выражение: [^\\P{P}-]+;\n",
        "            if not re.match('[^\\P{P}-]+', lemma):\n",
        "              lemma = re.sub('[^\\P{P}-]+', '', lemma).lower() # Привести полученные данные к нижнему регистру;\n",
        "              # Очистить полученные данные от стоп слов. Можно использовать nltk.corpus.stopwords;\n",
        "              if not lemma in stops:\n",
        "                lemms.append(lemma)\n",
        "                # fill word frquences dictionary\n",
        "                word_frequences_dict[lemma] = word_frequences_dict.get(lemma, 0) + 1\n",
        "                S += 1\n",
        "        for i in range(len(lemms) - 2):\n",
        "          trigrams.append((lemms[i], lemms[i+1], lemms[i+2]))\n",
        "          # fill trigram frquences dictionary\n",
        "          trigram_frequences_dict[trigrams[-1]] = trigram_frequences_dict.get(trigrams[-1], 0) + 1\n",
        "        text += ' '.join(lemms) + '.\\n'\n",
        "print(len(trigrams))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "8sWzEfeMDD3J"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "trigram_mi_scores_dict = dict()\n",
        "\n",
        "# calculate MI\n",
        "for trigram, trigram_freq in list(trigram_frequences_dict.items()):\n",
        "  lemm_1_freq = word_frequences_dict[trigram[0]]\n",
        "  lemm_2_freq = word_frequences_dict[trigram[1]]\n",
        "  lemm_3_freq = word_frequences_dict[trigram[2]]\n",
        "  trigram_mi_scores_dict[trigram] = math.log2(trigram_freq * (S**2) / (lemm_1_freq * lemm_2_freq * lemm_3_freq))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "S_wMoWnqmpfW",
        "outputId": "e6ac26cb-5384-4aa4-b751-61908dd25349"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "top 1-30 trigrams by mine MI\n",
            "('secondsfor', 'shiva', 'shankari') - MI = 43.4142033696431\n",
            "('desa', 'rueng', 'bakjok') - MI = 43.4142033696431\n",
            "('ratu', 'jope', 'seniloli') - MI = 43.4142033696431\n",
            "('fadhil', 'muhsen', 'salom') - MI = 43.4142033696431\n",
            "('prithviraj', 'chauhan', 'palam') - MI = 43.4142033696431\n",
            "('champa', 'devi', 'shukla') - MI = 43.4142033696431\n",
            "('prakash', 'sharan', 'mahat') - MI = 43.4142033696431\n",
            "('mihd', 'kahr', 'zeye') - MI = 43.4142033696431\n",
            "('realists', 'fantasist', 'rafat') - MI = 43.4142033696431\n",
            "('abdellah', 'hawari', 'believedto') - MI = 43.4142033696431\n",
            "('ewen', 'macaskill', 'inlondon') - MI = 43.4142033696431\n",
            "('floridasaying', 'vais', 'aider') - MI = 43.4142033696431\n",
            "('educationsuperintendent', 'inez', 'tenenbaum') - MI = 43.4142033696431\n",
            "('20744 ', 'toshinari', 'takaoka') - MI = 43.4142033696431\n",
            "('tunde', 'sanni', 'ilorin') - MI = 43.4142033696431\n",
            "('verissimo', 'correia', 'seabra') - MI = 43.4142033696431\n",
            "('madame', 'edmey', 'cimeus') - MI = 43.4142033696431\n",
            "('namo', 'narayan', 'meena') - MI = 43.4142033696431\n",
            "('bainum', 'outspent', 'mufi') - MI = 43.4142033696431\n",
            "('outspent', 'mufi', 'hannemann') - MI = 43.4142033696431\n",
            "('mufi', 'hannemann', 'honolulus') - MI = 43.4142033696431\n",
            "('marceal', 'miji', 'itengo') - MI = 43.4142033696431\n",
            "('miji', 'itengo', 'angolas') - MI = 43.4142033696431\n",
            "('jasbir', 'kang', 'yuba') - MI = 43.4142033696431\n",
            "('ducked', 'ohel', 'moishe') - MI = 43.4142033696431\n",
            "('phaithful', 'phlock', 'phinish') - MI = 43.4142033696431\n",
            "('polly', 'umrigar', 'dilip') - MI = 43.4142033696431\n",
            "('umrigar', 'dilip', 'vengsarkar') - MI = 43.4142033696431\n",
            "('dilip', 'vengsarkar', 'bapu') - MI = 43.4142033696431\n",
            "('vengsarkar', 'bapu', 'nadkarni') - MI = 43.4142033696431\n"
          ]
        }
      ],
      "source": [
        "# top-30 by mine MI\n",
        "sorted_mi_scores = sorted(trigram_mi_scores_dict.items(), key=lambda x: x[1], reverse=True)\n",
        "print('top 1-30 trigrams by mine MI')\n",
        "for trigram, mi_score in sorted_mi_scores[:30]:\n",
        "  print(f\"{trigram} - MI = {mi_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Ov3hvoX-dwgY",
        "outputId": "3faeeb6f-ff2a-42b5-d42f-0ae51f1c8209"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['alberta', 'say', 'public', 'inquiry', 'calgary', 'voting', 'scandal', 'press.', 'canadian', 'press']\n",
            "top 1-30 trigrams by nltk PMI\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.collocations import *\n",
        "from nltk.corpus import PlaintextCorpusReader\n",
        "\n",
        "trigram_measures = nltk.collocations.TrigramAssocMeasures()\n",
        "\n",
        "tokens = nltk.word_tokenize(text, 'english', True)\n",
        "print(tokens[:10])\n",
        "\n",
        "text = nltk.Text(tokens)\n",
        "\n",
        "#http://www.nltk.org/_modules/nltk/collocations.html\n",
        "finder_thr = TrigramCollocationFinder.from_words(text)\n",
        "\n",
        "print('top 1-30 trigrams by nltk PMI')\n",
        "thirty_best_trigrams_nltk = finder_thr.nbest(trigram_measures.pmi, 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VrPvoGzGdA2E",
        "outputId": "514026b1-9876-4814-f470-a49f58890d03"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('0005173', 'miami050', '0004287'),\n",
              " ('0009875', 'buffalo040', '0005173'),\n",
              " ('20744', 'toshinari', 'takaoka'),\n",
              " ('318245', '2819', 'yearling.'),\n",
              " ('46645', 'spellsquot', 'googl'),\n",
              " ('7roger', 'sooley', 'compstar'),\n",
              " ('a=maw', 's=mobile20and20wireless20technology', 'o=fptgt'),\n",
              " ('abdellah', 'hawari', 'believedto'),\n",
              " ('abend', 'einem', 'offiziellen'),\n",
              " ('abolishes', 'preallocation', 'tyranny.'),\n",
              " ('accountsalmost', 'identically', 'devoting'),\n",
              " ('adatta', 'agli', 'ultimi'),\n",
              " ('adda', 'addb', 'addc'),\n",
              " ('ampex.', 'sonyand', 'ampexhave'),\n",
              " ('andkawasaki', 'kisen', 'kaisha'),\n",
              " ('andrival', 'kalle', 'palander'),\n",
              " ('anieres', 'cologny', 'carouge'),\n",
              " ('annuncia', 'nuova', 'tecnologiaquot'),\n",
              " ('anpac', 'unione', 'piloti.'),\n",
              " ('arepair', 'keycache', 'strate.'),\n",
              " ('arraylist3', 'adda', 'addb'),\n",
              " ('aspwiki', 'snipsnap', 'aswiki'),\n",
              " ('aswiki', 'egroupwarewiki', 'hiki'),\n",
              " ('bainum', 'outspent', 'mufi'),\n",
              " ('balsamic', 'viniggas', 'trollaxors'),\n",
              " ('bassiana', 'metarhizium', 'anisopliae.'),\n",
              " ('bayerische', 'motoren', 'werke'),\n",
              " ('beauveria', 'bassiana', 'metarhizium'),\n",
              " ('betancor', 'javi', 'venta'),\n",
              " ('beverlys', 'nicki', 'silveira')]"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "thirty_best_trigrams_nltk"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}