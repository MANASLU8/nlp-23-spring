{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Erellnuc4aW7",
        "outputId": "137ec236-0e5c-41e3-e03d-250bc3e2d495"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.9.16\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IO2MFOvddjPQ",
        "outputId": "9aa801d3-f98b-4ac8-d017-868f7c07d87d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "train_url = 'gdrive/My Drive/Colab Notebooks/nlp-2023/train.csv'\n",
        "test_url = 'gdrive/My Drive/Colab Notebooks/nlp-2023/test.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M82NzQ54ePiK"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df_train = pd.read_csv(train_url)\n",
        "df_test = pd.read_csv(test_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "jnrElDr-ebXK",
        "outputId": "7b744667-9cef-4338-fa87-01003042e048"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        class                                              title  \\\n",
              "0           3  Wall St. Bears Claw Back Into the Black (Reuters)   \n",
              "1           3  Carlyle Looks Toward Commercial Aerospace (Reu...   \n",
              "2           3    Oil and Economy Cloud Stocks' Outlook (Reuters)   \n",
              "3           3  Iraq Halts Oil Exports from Main Southern Pipe...   \n",
              "4           3  Oil prices soar to all-time record, posing new...   \n",
              "...       ...                                                ...   \n",
              "119995      1  Pakistan's Musharraf Says Won't Quit as Army C...   \n",
              "119996      2                  Renteria signing a top-shelf deal   \n",
              "119997      2                    Saban not going to Dolphins yet   \n",
              "119998      2                                  Today's NFL games   \n",
              "119999      2                       Nets get Carter from Raptors   \n",
              "\n",
              "                                                     text  \n",
              "0       Reuters - Short-sellers, Wall Street's dwindli...  \n",
              "1       Reuters - Private investment firm Carlyle Grou...  \n",
              "2       Reuters - Soaring crude prices plus worries\\ab...  \n",
              "3       Reuters - Authorities have halted oil export\\f...  \n",
              "4       AFP - Tearaway world oil prices, toppling reco...  \n",
              "...                                                   ...  \n",
              "119995   KARACHI (Reuters) - Pakistani President Perve...  \n",
              "119996  Red Sox general manager Theo Epstein acknowled...  \n",
              "119997  The Miami Dolphins will put their courtship of...  \n",
              "119998  PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...  \n",
              "119999  INDIANAPOLIS -- All-Star Vince Carter was trad...  \n",
              "\n",
              "[120000 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd517a31-beaf-4c5e-958f-1336823c786c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>Wall St. Bears Claw Back Into the Black (Reuters)</td>\n",
              "      <td>Reuters - Short-sellers, Wall Street's dwindli...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>3</td>\n",
              "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
              "      <td>Reuters - Private investment firm Carlyle Grou...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters)</td>\n",
              "      <td>Reuters - Soaring crude prices plus worries\\ab...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
              "      <td>Reuters - Authorities have halted oil export\\f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>Oil prices soar to all-time record, posing new...</td>\n",
              "      <td>AFP - Tearaway world oil prices, toppling reco...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119995</th>\n",
              "      <td>1</td>\n",
              "      <td>Pakistan's Musharraf Says Won't Quit as Army C...</td>\n",
              "      <td>KARACHI (Reuters) - Pakistani President Perve...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119996</th>\n",
              "      <td>2</td>\n",
              "      <td>Renteria signing a top-shelf deal</td>\n",
              "      <td>Red Sox general manager Theo Epstein acknowled...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119997</th>\n",
              "      <td>2</td>\n",
              "      <td>Saban not going to Dolphins yet</td>\n",
              "      <td>The Miami Dolphins will put their courtship of...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119998</th>\n",
              "      <td>2</td>\n",
              "      <td>Today's NFL games</td>\n",
              "      <td>PITTSBURGH at NY GIANTS Time: 1:30 p.m. Line: ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119999</th>\n",
              "      <td>2</td>\n",
              "      <td>Nets get Carter from Raptors</td>\n",
              "      <td>INDIANAPOLIS -- All-Star Vince Carter was trad...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>120000 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd517a31-beaf-4c5e-958f-1336823c786c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cd517a31-beaf-4c5e-958f-1336823c786c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cd517a31-beaf-4c5e-958f-1336823c786c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "lRVJyVFLXoO3",
        "outputId": "a3f7053f-e4b2-40ed-ddda-f823806d4be2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      class                                              title  \\\n",
              "0         3                  Fears for T N pension after talks   \n",
              "1         4  The Race is On: Second Private Team Sets Launc...   \n",
              "2         4      Ky. Company Wins Grant to Study Peptides (AP)   \n",
              "3         4      Prediction Unit Helps Forecast Wildfires (AP)   \n",
              "4         4        Calif. Aims to Limit Farm-Related Smog (AP)   \n",
              "...     ...                                                ...   \n",
              "7595      1                                   Around the world   \n",
              "7596      2                        Void is filled with Clement   \n",
              "7597      2                             Martinez leaves bitter   \n",
              "7598      3  5 of arthritis patients in Singapore take Bext...   \n",
              "7599      3                             EBay gets into rentals   \n",
              "\n",
              "                                                   text  \n",
              "0     Unions representing workers at Turner   Newall...  \n",
              "1     SPACE.com - TORONTO, Canada -- A second\\team o...  \n",
              "2     AP - A company founded by a chemistry research...  \n",
              "3     AP - It's barely dawn when Mike Fitzpatrick st...  \n",
              "4     AP - Southern California's smog-fighting agenc...  \n",
              "...                                                 ...  \n",
              "7595  Ukrainian presidential candidate Viktor Yushch...  \n",
              "7596  With the supply of attractive pitching options...  \n",
              "7597  Like Roger Clemens did almost exactly eight ye...  \n",
              "7598  SINGAPORE : Doctors in the United States have ...  \n",
              "7599  EBay plans to buy the apartment and home renta...  \n",
              "\n",
              "[7600 rows x 3 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ba6e5bec-730f-4bec-882a-a0beb086497d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>class</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>Fears for T N pension after talks</td>\n",
              "      <td>Unions representing workers at Turner   Newall...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>The Race is On: Second Private Team Sets Launc...</td>\n",
              "      <td>SPACE.com - TORONTO, Canada -- A second\\team o...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4</td>\n",
              "      <td>Ky. Company Wins Grant to Study Peptides (AP)</td>\n",
              "      <td>AP - A company founded by a chemistry research...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>Prediction Unit Helps Forecast Wildfires (AP)</td>\n",
              "      <td>AP - It's barely dawn when Mike Fitzpatrick st...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Calif. Aims to Limit Farm-Related Smog (AP)</td>\n",
              "      <td>AP - Southern California's smog-fighting agenc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7595</th>\n",
              "      <td>1</td>\n",
              "      <td>Around the world</td>\n",
              "      <td>Ukrainian presidential candidate Viktor Yushch...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7596</th>\n",
              "      <td>2</td>\n",
              "      <td>Void is filled with Clement</td>\n",
              "      <td>With the supply of attractive pitching options...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7597</th>\n",
              "      <td>2</td>\n",
              "      <td>Martinez leaves bitter</td>\n",
              "      <td>Like Roger Clemens did almost exactly eight ye...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7598</th>\n",
              "      <td>3</td>\n",
              "      <td>5 of arthritis patients in Singapore take Bext...</td>\n",
              "      <td>SINGAPORE : Doctors in the United States have ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7599</th>\n",
              "      <td>3</td>\n",
              "      <td>EBay gets into rentals</td>\n",
              "      <td>EBay plans to buy the apartment and home renta...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7600 rows × 3 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ba6e5bec-730f-4bec-882a-a0beb086497d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ba6e5bec-730f-4bec-882a-a0beb086497d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ba6e5bec-730f-4bec-882a-a0beb086497d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eeeGeDtM5NqW"
      },
      "outputs": [],
      "source": [
        "import re # https://docs-python.ru/standart-library/modul-re-python/sintaksis-reguljarnogo-vyrazhenija/\n",
        "\n",
        "# regesы расположены в порядке приоритета\n",
        "\n",
        "# $15trln ; $15 trln ; $15,000 ; $15 ; $15.2 ; $1.8bn ; $1 mn ; $0.49 ; $1.033 billion\n",
        "money_in_bucks_regex = r'\\$\\s?\\d+(?:\\,\\d{3})?(?:\\.\\d+)?\\s?(?:trillion|billion|million|thousand|trln|bn|mn|th)?'\n",
        "# телефоны - The phone number for the New York sports desk is (212) 621-1630 ; (800-838-4616) ; \n",
        "phone_regex = r'\\({1}\\d{10}\\){1}|\\({0,1}\\d{3}[\\-\\s]\\d{3}[\\-\\s]\\d{4}\\){0,1}|\\(\\d{3}\\)\\s\\d{3}-\\d{4}|\\({1}\\d{3}-\\d{3}-\\d{4}\\){1}'\n",
        "# дата - Aug. 17 ; Aug 17 ; Jan. 2000 ; 5-Feb-2019 ; 05/02/2019 ; 05-02-19 ; 05.02.2019 ;  5 Feb 2019 ; 5 Feb. 19 ; 5 February 19 ; Feb. 1, 2003\n",
        "date_regex = r'[0-9]{0,2}[.\\-\\s]{0,1}January\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}February\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}March\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}April\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}May\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}June\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}July\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}August\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}September\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}October\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}November\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}December\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}Jan\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}Feb\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}Mar\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}Apr\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}May\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}Jun\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}Jul\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}Aug\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}Sep\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}Oct\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}Nov\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\-\\s]{0,1}Dec\\.?[.\\-\\s]{0,1}[0-9]{1,4}|[0-9]{2}[\\-.\\/][0-9]{2}[\\-.\\/][0-9]{2,4}'\n",
        "# время - 1:54.04 ; 1:30 pm ; 9:03 ; 00:00:00 ; 3:15 a.m.\n",
        "time_regex = r'\\d{0,2}:{0,1}\\d{0,2}:{0,1}\\d{2}\\.{0,1}\\d{0,3}\\s{0,1}pm|\\d{0,2}:{0,1}\\d{0,2}:{0,1}\\d{2}\\.{0,1}\\d{0,3}\\s{0,1}p\\.m\\.|\\d{0,2}:{0,1}\\d{0,2}:{0,1}\\d{2}\\.{0,1}\\d{0,3}\\s{0,1}am|\\d{0,2}:{0,1}\\d{0,2}:{0,1}\\d{2}\\.{0,1}\\d{0,3}\\s{0,1}a\\.m\\.|\\d{0,2}:{0,1}\\d{0,2}:{0,1}\\d{2}\\.{0,1}\\d{0,3}\\s{0,1}'\n",
        "# 81kg ; 1 km\n",
        "unit_of_measure_regex = r'\\d{1,}\\.?\\d?\\s?kg|\\d{1,}\\.?\\d?\\s?mg|\\d{1,}\\.?\\d?\\s?g|\\d{1,}\\.?\\d?\\s?t|\\d{1,}\\.?\\d?\\s?ton|\\d{1,}\\.?\\d?\\s?in|\\d{1,}\\.?\\d?\\s?ft|\\d{1,}\\.?\\d?\\s?yard|\\d{1,}\\.?\\d?\\s?mile|\\d{1,}\\.?\\d?\\s?m|\\d{1,}\\.?\\d?\\s?cm|\\d{1,}\\.?\\d?\\s?km|\\d{1,}\\.?\\d?\\s?mm|\\d{1,}\\.?\\d?\\s?oz|\\d{1,}\\.?\\d?\\s?lb|\\d{1,}\\.?\\d?\\s?l|\\d{1,}\\.?\\d?\\s?gal|\\d{1,}\\.?\\d?\\s?pt|\\d{1,}\\.?\\d?\\s?C|\\d{1,}\\.?\\d?\\s?F|\\d{1,}\\.?\\d?\\s?K|\\d{1,}\\.?\\d?\\s?W|\\d{1,}\\.?\\d?\\s?bar|\\d{1,}\\.?\\d?\\s?a|\\d{1,}\\.?\\d?\\s?ha|\\d{1,}\\.?\\d?\\s?Hz|\\d{1,}\\.?\\d?\\s?GHz|\\d{1,}\\.?\\d?\\s?J|\\d{1,}\\.?\\d?\\s?kW|\\d{1,}\\.?\\d?\\s?s|\\d{1,}\\.?\\d?\\s?ms|\\d{1,}\\.?\\d?\\s?ns|\\d{1,}\\.?\\d?\\s?h|\\d{1,}\\.?\\d?\\s?q|\\d{1,}\\.?\\d?\\s?rad|\\d{1,}\\.?\\d?\\s?Pa|\\d{1,}\\.?\\d?\\s?pc|\\d{1,}\\.?\\d?\\s?N|\\d{1,}\\.?\\d?\\s?min|\\d{1,}\\.?\\d?\\s?A|\\d{1,}\\.?\\d?\\s?V|\\d{1,}\\.?\\d?\\s?GW|\\d{1,}\\.?\\d?\\s?MW|\\d{1,}\\.?\\d?\\s?TW|\\d{1,}\\.?\\d?\\s?C|\\d{1,}\\.?\\d?\\s?Mx|\\d{1,}\\.?\\d?\\s?MeV|\\d{1,}\\.?\\d?\\s?cd|\\d{1,}\\.?\\d?\\s?lx|\\d{1,}\\.?\\d?\\s?lm'\n",
        "# email - bebra-shmebrikovna.reks3-4-4@yarus34.ru\n",
        "email_address_regex = r'[A-z0-9\\-]{1,}\\.{0,1}[A-z0-9]+@[A-z0-9]+\\.{1,}[A-z0-9]{1,6}'\n",
        "# веб-адреса - http://yourap.org/ ; For-Side.com ; https://colab.research.google.com/drive/1d3ge137zLqANxnbj4XVU0GGc9_IwDfIg?authuser=1#scrollTo=eeeGeDtM5NqW\n",
        "web_address_regex = r'https?:\\/\\/{0,1}[w]{0,3}\\.{0,1}(?:[A-z0-9]+\\.){1,}[A-z0-9]{1,6}(?:\\/[A-z0-9]{1,}){0,}'\n",
        "# компании с сокращениями - Google inc. ; General Motors Corp. ; Halliburton Co. ; Louisiana-Pacific Corp.\n",
        "company_name_regex = r'(?:[A-Z][a-z]*(?:-|\\s)?)+\\s(?:[Ii]nc.|[Cc]orp.|[Ll]td|[Pp]lc\\.|Co\\.)'\n",
        "# номер - No. 21 ; 42 carries, leading No. 12 Kansas State to a season-opening. ;  leading No. 3 Georgia \n",
        "no_regex = r'[Nn]o.\\s?\\d+'\n",
        "# сокращения через точку - M.V.P. ; S.E.C.\n",
        "shorts_regex = r'(?:[A-Z][a-z]{0,2}\\.)+'\n",
        "# простые слова из букв\n",
        "word_regex = r'[A-z]+'\n",
        "# TODO - пунктуация(тоже выносим в токены) - \" - \" __ \": \" __ \"; \" __ \"! \" __ \"? \" __ \". \" __ \", \" ___ \"...\"\n",
        "punctuation_regex = r'[.!?\\-;:]{1,3}'\n",
        "# для разделения по рпобелам\n",
        "not_space_regex = r'[^\\s.!?\\-;:]+' # any not space symbol sequence\n",
        "\n",
        "# сплит по предложениям\n",
        "sentence_split_regex = r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?|!)\\s(?![a-z])'\n",
        "# для замены кода доллара на его знак\n",
        "dollar_code_sub_regex = r'(#36;|\\\\\\$)'\n",
        "# очистка от мусора заменой на пробел\n",
        "clear_sub_regex = r'[\\-\\\\]{2,}|\\\\|\\s{2,}'\n",
        "\n",
        "# распределить по приоритету, вроде бы та регулярка что идёт первее, матчится в первую очередь\n",
        "regex_to_take_tokens = money_in_bucks_regex + '|' + phone_regex + '|' + date_regex + '|' + time_regex + '|' + email_address_regex + '|' + web_address_regex + '|' + company_name_regex + '|' + no_regex + '|' + shorts_regex + '|' + punctuation_regex + '|' + not_space_regex"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Тестирование regexов"
      ],
      "metadata": {
        "id": "Uhp-V8x1avOI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# проверка регексов\n",
        "\n",
        "bucks_regex_url = 'gdrive/My Drive/Colab Notebooks/nlp-2023/regex-checking/bucks-regex-testing.tsv'\n",
        "clear_regex_url = 'gdrive/My Drive/Colab Notebooks/nlp-2023/regex-checking/clear-regex-testing.tsv'\n",
        "company_name_regex_url = 'gdrive/My Drive/Colab Notebooks/nlp-2023/regex-checking/company-name-regex-testing.tsv'\n",
        "date_regex_url = 'gdrive/My Drive/Colab Notebooks/nlp-2023/regex-checking/date-regex-testing.tsv'\n",
        "doller_subtitution_regex_url = 'gdrive/My Drive/Colab Notebooks/nlp-2023/regex-checking/doller-subtitution-regex-testing.tsv'\n",
        "email_regex_url = 'gdrive/My Drive/Colab Notebooks/nlp-2023/regex-checking/email-regex-testing.tsv'\n",
        "final_regex_url = 'gdrive/My Drive/Colab Notebooks/nlp-2023/regex-checking/final-regex-testing.tsv'\n",
        "not_space_regex_url = 'gdrive/My Drive/Colab Notebooks/nlp-2023/regex-checking/not-space-regex-testing.tsv'\n",
        "phone_regex_url = 'gdrive/My Drive/Colab Notebooks/nlp-2023/regex-checking/phone-regex-testing.tsv'\n",
        "punctuation_regex_url = 'gdrive/My Drive/Colab Notebooks/nlp-2023/regex-checking/punctuation-regex-testing.tsv'\n",
        "sentence_split_regex_url = 'gdrive/My Drive/Colab Notebooks/nlp-2023/regex-checking/sentence-split-regex-testing.tsv'\n",
        "serial_number_regex_url = 'gdrive/My Drive/Colab Notebooks/nlp-2023/regex-checking/serial-number-regex-testing.tsv'\n",
        "shorts_regex_url = 'gdrive/My Drive/Colab Notebooks/nlp-2023/regex-checking/shorts-regex-testing.tsv'\n",
        "time_regex_url = 'gdrive/My Drive/Colab Notebooks/nlp-2023/regex-checking/time-regex-testing.tsv'\n",
        "units_of_measure_regex_url = 'gdrive/My Drive/Colab Notebooks/nlp-2023/regex-checking/units-of-measure-regex-testing.tsv'\n",
        "web_address_regex_url = 'gdrive/My Drive/Colab Notebooks/nlp-2023/regex-checking/web-address-regex-testing.tsv'\n",
        "word_regex_url = 'gdrive/My Drive/Colab Notebooks/nlp-2023/regex-checking/word-regex-testing.tsv'\n",
        "\n",
        "bucks_regex_df = pd.read_csv(bucks_regex_url, sep='\\t')\n",
        "clear_regex_df = pd.read_csv(clear_regex_url, sep='\\t')\n",
        "company_name_regex_df = pd.read_csv(company_name_regex_url, sep='\\t')\n",
        "date_regex_df = pd.read_csv(date_regex_url, sep='\\t')\n",
        "doller_subtitution_regex_df = pd.read_csv(doller_subtitution_regex_url, sep='\\t')\n",
        "email_regex_df = pd.read_csv(email_regex_url, sep='\\t')\n",
        "final_regex_df = pd.read_csv(final_regex_url, sep='\\t')\n",
        "not_space_regex_df = pd.read_csv(not_space_regex_url, sep='\\t')\n",
        "phone_regex_df = pd.read_csv(phone_regex_url, sep='\\t')\n",
        "punctuation_regex_df = pd.read_csv(punctuation_regex_url, sep='\\t')\n",
        "sentence_split_regex_df = pd.read_csv(sentence_split_regex_url, sep='\\t')\n",
        "serial_number_regex_df = pd.read_csv(serial_number_regex_url, sep='\\t')\n",
        "shorts_regex_df = pd.read_csv(shorts_regex_url, sep='\\t')\n",
        "time_regex_df = pd.read_csv(time_regex_url, sep='\\t')\n",
        "units_of_measure_regex_df = pd.read_csv(units_of_measure_regex_url, sep='\\t')\n",
        "web_address_regex_df = pd.read_csv(web_address_regex_url, sep='\\t')\n",
        "word_regex_df = pd.read_csv(word_regex_url, sep='\\t')"
      ],
      "metadata": {
        "id": "uW4H87RaS8vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for index, row in bucks_regex_df.iterrows():\n",
        "  result = re.findall(money_in_bucks_regex, row['example'])\n",
        "  result_str = ''\n",
        "  for token in result:\n",
        "    result_str = result_str + token + ';'\n",
        "  result_str = result_str[:-1]\n",
        "  test_result = result_str == row['expected']\n",
        "  print(f\"money_in_bucks_regex passed test: {test_result}\")\n",
        "\n",
        "for index, row in clear_regex_df.iterrows():\n",
        "  result = re.findall(clear_sub_regex, row['example'])\n",
        "  result_str = ''\n",
        "  for token in result:\n",
        "    result_str = result_str + token + ';'\n",
        "  result_str = result_str[:-1]\n",
        "  test_result = result_str == row['expected']\n",
        "  print(f\"clear_sub_regex passed test: {test_result}\")\n",
        "\n",
        "for index, row in company_name_regex_df.iterrows():\n",
        "  result = re.findall(company_name_regex, row['example'])\n",
        "  result_str = ''\n",
        "  for token in result:\n",
        "    result_str = result_str + token + ';'\n",
        "  result_str = result_str[:-1]\n",
        "  test_result = result_str == row['expected']\n",
        "  print(f\"company_name_regex passed test: {test_result}\")\n",
        "\n",
        "for index, row in date_regex_df.iterrows():\n",
        "  result = re.findall(date_regex, row['example'])\n",
        "  result_str = ''\n",
        "  for token in result:\n",
        "    result_str = result_str + token + ';'\n",
        "  result_str = result_str[:-1]\n",
        "  test_result = result_str == row['expected']\n",
        "  print(f\"date_regex passed test: {test_result}\")\n",
        "\n",
        "for index, row in doller_subtitution_regex_df.iterrows():\n",
        "  result = re.findall(dollar_code_sub_regex, row['example'])\n",
        "  result_str = ''\n",
        "  for token in result:\n",
        "    result_str = result_str + token + ';'\n",
        "  result_str = result_str[:-1]\n",
        "  test_result = result_str == row['expected']\n",
        "  print(f\"dollar_code_sub_regex passed test: {test_result}\")\n",
        "\n",
        "for index, row in email_regex_df.iterrows():\n",
        "  result = re.findall(email_address_regex, row['example'])\n",
        "  result_str = ''\n",
        "  for token in result:\n",
        "    result_str = result_str + token + ';'\n",
        "  result_str = result_str[:-1]\n",
        "  test_result = result_str == row['expected']\n",
        "  print(f\"email_address_regex passed test: {test_result}\")\n",
        "\n",
        "for index, row in final_regex_df.iterrows():\n",
        "  result = re.findall(regex_to_take_tokens, row['example'])\n",
        "  result_str = ''\n",
        "  for token in result:\n",
        "    result_str = result_str + token + ';'\n",
        "  result_str = result_str[:-1]\n",
        "  test_result = result_str == row['expected']\n",
        "  print(f\"regex_to_take_tokens passed test: {test_result}\")\n",
        "\n",
        "for index, row in not_space_regex_df.iterrows():\n",
        "  result = re.findall(not_space_regex, row['example'])\n",
        "  result_str = ''\n",
        "  for token in result:\n",
        "    result_str = result_str + token + ';'\n",
        "  result_str = result_str[:-1]\n",
        "  test_result = result_str == row['expected']\n",
        "  print(f\"not_space_regex passed test: {test_result}\")\n",
        "\n",
        "for index, row in phone_regex_df.iterrows():\n",
        "  result = re.findall(phone_regex, row['example'])\n",
        "  result_str = ''\n",
        "  for token in result:\n",
        "    result_str = result_str + token + ';'\n",
        "  result_str = result_str[:-1]\n",
        "  test_result = result_str == row['expected']\n",
        "  print(f\"phone_regex passed test: {test_result}\")\n",
        "\n",
        "for index, row in punctuation_regex_df.iterrows():\n",
        "  result = re.findall(punctuation_regex, row['example'])\n",
        "  result_str = ''\n",
        "  for token in result:\n",
        "    result_str = result_str + token + ';'\n",
        "  result_str = result_str[:-1]\n",
        "  test_result = result_str == row['expected']\n",
        "  print(f\"punctuation_regex passed test: {test_result}\")\n",
        "\n",
        "for index, row in sentence_split_regex_df.iterrows():\n",
        "  result = re.findall(sentence_split_regex, row['example'])\n",
        "  result_str = ''\n",
        "  for token in result:\n",
        "    result_str = result_str + token + ';'\n",
        "  result_str = result_str[:-1]\n",
        "  test_result = result_str == row['expected']\n",
        "  print(f\"sentence_split_regex passed test: {test_result}\")\n",
        "\n",
        "for index, row in serial_number_regex_df.iterrows():\n",
        "  result = re.findall(no_regex, row['example'])\n",
        "  result_str = ''\n",
        "  for token in result:\n",
        "    result_str = result_str + token + ';'\n",
        "  result_str = result_str[:-1]\n",
        "  test_result = result_str == row['expected']\n",
        "  print(f\"no_regex passed test: {test_result}\")\n",
        "\n",
        "for index, row in shorts_regex_df.iterrows():\n",
        "  result = re.findall(shorts_regex, row['example'])\n",
        "  result_str = ''\n",
        "  for token in result:\n",
        "    result_str = result_str + token + ';'\n",
        "  result_str = result_str[:-1]\n",
        "  test_result = result_str == row['expected']\n",
        "  print(f\"shorts_regex passed test: {test_result}\")\n",
        "\n",
        "for index, row in time_regex_df.iterrows():\n",
        "  result = re.findall(time_regex, row['example'])\n",
        "  result_str = ''\n",
        "  for token in result:\n",
        "    result_str = result_str + token + ';'\n",
        "  result_str = result_str[:-1]\n",
        "  test_result = result_str == row['expected']\n",
        "  print(f\"time_regex passed test: {test_result}\")\n",
        "\n",
        "for index, row in units_of_measure_regex_df.iterrows():\n",
        "  result = re.findall(unit_of_measure_regex, row['example'])\n",
        "  result_str = ''\n",
        "  for token in result:\n",
        "    result_str = result_str + token + ';'\n",
        "  result_str = result_str[:-1]\n",
        "  test_result = result_str == row['expected']\n",
        "  print(f\"unit_of_measure_regex passed test: {test_result}\")\n",
        "\n",
        "for index, row in web_address_regex_df.iterrows():\n",
        "  result = re.findall(web_address_regex, row['example'])\n",
        "  result_str = ''\n",
        "  for token in result:\n",
        "    result_str = result_str + token + ';'\n",
        "  result_str = result_str[:-1]\n",
        "  test_result = result_str == row['expected']\n",
        "  print(f\"web_address_regex passed test: {test_result}\")\n",
        "\n",
        "for index, row in word_regex_df.iterrows():\n",
        "  result = re.findall(word_regex, row['example'])\n",
        "  result_str = ''\n",
        "  for token in result:\n",
        "    result_str = result_str + token + ';'\n",
        "  result_str = result_str[:-1]\n",
        "  test_result = result_str == row['expected']\n",
        "  print(f\"word_regex passed test: {test_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n-gclphpbKBj",
        "outputId": "7e5f90b5-5808-49b6-95af-27c0cbd910ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "money_in_bucks_regex passed test: True\n",
            "clear_sub_regex passed test: False\n",
            "company_name_regex passed test: True\n",
            "date_regex passed test: True\n",
            "dollar_code_sub_regex passed test: True\n",
            "email_address_regex passed test: True\n",
            "regex_to_take_tokens passed test: True\n",
            "not_space_regex passed test: True\n",
            "phone_regex passed test: True\n",
            "punctuation_regex passed test: True\n",
            "sentence_split_regex passed test: True\n",
            "no_regex passed test: False\n",
            "shorts_regex passed test: True\n",
            "time_regex passed test: False\n",
            "unit_of_measure_regex passed test: True\n",
            "web_address_regex passed test: False\n",
            "word_regex passed test: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "id": "PuToXcRhY9pv",
        "outputId": "b0d5c8ee-2737-4401-c8bc-98c48fa46748"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\\\$\\\\s?\\\\d+(?:\\\\,\\\\d{3})?(?:\\\\.\\\\d+)?\\\\s?(?:trillion|billion|million|thousand|trln|bn|mn|th)?|\\\\({1}\\\\d{10}\\\\){1}|\\\\({0,1}\\\\d{3}[\\\\-\\\\s]\\\\d{3}[\\\\-\\\\s]\\\\d{4}\\\\){0,1}|\\\\(\\\\d{3}\\\\)\\\\s\\\\d{3}-\\\\d{4}|\\\\({1}\\\\d{3}-\\\\d{3}-\\\\d{4}\\\\){1}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}January\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}February\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}March\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}April\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}May\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}June\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}July\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}August\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}September\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}October\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}November\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}December\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}Jan\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}Feb\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}Mar\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}Apr\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}May\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}Jun\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}Jul\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}Aug\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}Sep\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}Oct\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}Nov\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{0,2}[.\\\\-\\\\s]{0,1}Dec\\\\.?[.\\\\-\\\\s]{0,1}[0-9]{1,4}|[0-9]{2}[\\\\-.\\\\/][0-9]{2}[\\\\-.\\\\/][0-9]{2,4}|\\\\d{0,2}:{0,1}\\\\d{0,2}:{0,1}\\\\d{2}\\\\.{0,1}\\\\d{0,3}\\\\s{0,1}pm|\\\\d{0,2}:{0,1}\\\\d{0,2}:{0,1}\\\\d{2}\\\\.{0,1}\\\\d{0,3}\\\\s{0,1}p\\\\.m\\\\.|\\\\d{0,2}:{0,1}\\\\d{0,2}:{0,1}\\\\d{2}\\\\.{0,1}\\\\d{0,3}\\\\s{0,1}am|\\\\d{0,2}:{0,1}\\\\d{0,2}:{0,1}\\\\d{2}\\\\.{0,1}\\\\d{0,3}\\\\s{0,1}a\\\\.m\\\\.|\\\\d{0,2}:{0,1}\\\\d{0,2}:{0,1}\\\\d{2}\\\\.{0,1}\\\\d{0,3}\\\\s{0,1}|[A-z0-9\\\\-]{1,}\\\\.{0,1}[A-z0-9]+@[A-z0-9]+\\\\.{1,}[A-z0-9]{1,6}|https?:\\\\/\\\\/{0,1}[w]{0,3}\\\\.{0,1}(?:[A-z0-9]+\\\\.){1,}[A-z0-9]{1,6}(?:\\\\/[A-z0-9]{1,}){0,}|(?:[A-Z][a-z]*(?:-|\\\\s)?)+\\\\s(?:[Ii]nc.|[Cc]orp.|[Ll]td|[Pp]lc\\\\.|Co\\\\.)|[Nn]o.\\\\s?\\\\d+|(?:[A-Z][a-z]{0,2}\\\\.)+|[.!?\\\\-;:]{1,3}|[^\\\\s.!?\\\\-;:]+'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "regex_to_take_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qcv772OsYbmU"
      },
      "outputs": [],
      "source": [
        "current_test = '# $15trln ; $15 trln ; $15,000 ; $15 ; $15.2 ; $1.8bn ; $1 mn ; $0.49 ; $1.033 billion # 81kg ; 1 km # телефоны - The phone number for the New York sports desk is (212) 621-1630 ; (800-838-4616) ;  # дата - Aug. 17 ; Aug 17 ; Jan. 2000 ; 5-Feb-2019 ; 05/02/2019 ; 05-02-19 ; 05.02.2019 ;  5 Feb 2019 ; 5 Feb. 19 ; 5 February 19 ;  # время - 1:54.04 ; 1:30 pm ; 9:03 ; 00:00:00 ; 3:15 a.m. # веб-адреса - http://yourap.org/ ; For-Side.com ; https://colab.research.google.com/dfghldkfjhgld/dfgjlkdkjf/798df # компании с сокращениями - Google inc. ; General Motors Corp. ; Halliburton Co. ; Louisiana-Pacific Corp. # email - bebra-shmebrikovna.reks3-4-4@yarus34.ru # код цвета - #666666 # номер - No. 21 ; 42 carries, leading No. 12 Kansas State to a season-opening. ;  leading No. 3 Georgia  # сокращения через точку - M.V.P. ; S.E.C. # TODO - пунктуация(тоже выносим в токены) - \" - \" __ \": \" __ \"; \" __ \"! \" __ \"? \" __ \". \" __ \", \" ___ \"...\" Bebrikeevna shembra. Reks Shemksovich... Default chan!'\n",
        "res = re.findall(regex_to_take_tokens, current_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwXLZTk5WAiA"
      },
      "outputs": [],
      "source": [
        "# смотрим результат итогового регекса\n",
        "res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ysWyNqvLmlg"
      },
      "outputs": [],
      "source": [
        "# проверяем как работает сплит на предложения\n",
        "test_sentences_split = 'Bebrou girik at 5 a.m. smebrik lorem No.12 tovar No. 4 Gelentwagen! Evil corp. develop notebook? Shark attac on the road just mobile central park for young Trash. Germany vs Chemicals. one of our new categories in the APMF Sense of Place survey is for best Asian business city. After a couple of days, Singapore leads the pack, followed by Bangkok, Thailand and Hong Kong. Enter your vote and comments and make your views count. More new categories include best city for livability, and best tourism destinations.'\n",
        "result = re.split(sentence_split_regex, test_sentences_split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3EjDfOckMvNI",
        "outputId": "d9a03933-1f58-412c-8c1c-b0a91084c23f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Bebrou girik at 5 a.m. smebrik lorem No.12 tovar No. 4 Gelentwagen!',\n",
              " 'Evil corp. develop notebook?',\n",
              " 'Shark attac on the road just mobile central park for young Trash.',\n",
              " 'Germany vs Chemicals. one of our new categories in the APMF Sense of Place survey is for best Asian business city.',\n",
              " 'After a couple of days, Singapore leads the pack, followed by Bangkok, Thailand and Hong Kong.',\n",
              " 'Enter your vote and comments and make your views count.',\n",
              " 'More new categories include best city for livability, and best tourism destinations.']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIhRIKnAvaGs"
      },
      "source": [
        "# Проверка отчистки предложения от мусора и замены всякого"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__5dVnTGvjyV"
      },
      "outputs": [],
      "source": [
        "test_substitute = '\\\\I\\'ve been a big fan of Log4J for a while now but haven\\'t migrated any code\\over for one central reason. The following line of code:\\\\ final static Logger logger = Logger.getLogger( \"some.name\" );\\\\... is amazingly ugly and difficult to work with.\\\\Most people use Log4J with a logger based on the classname:\\\\So we would probably see:\\\\ static Logger logger = Logger.getLogger( \"org.apache.commons.feedparser.locate.FeedLocator\" );\\\\Which is amazingly verbose. A lot of developers shorten this to:\\\\ static Logger logger = Logger.getLogger( FeedLocator.class );\\\\But this still leaves us with cut and paste errors.\\\\What if we could just reduce it to:\\\\ static Logger logger = Logger.g ...\\\\'\n",
        "result = re.sub(dollar_code_sub_regex, '$', test_substitute)\n",
        "result = re.sub(clear_sub_regex, '', test_substitute)\n",
        "result = re.sub(clear_sub_regex, '', test_substitute)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "GzLDT5EDJiUN",
        "outputId": "864f693a-7611-46b8-901f-3966974b960c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'I\\'ve been a big fan of Log4J for a while now but haven\\'t migrated any codeover for one central reason. The following line of code: final static Logger logger = Logger.getLogger( \"some.name\" );... is amazingly ugly and difficult to work with.Most people use Log4J with a logger based on the classname:So we would probably see: static Logger logger = Logger.getLogger( \"org.apache.commons.feedparser.locate.FeedLocator\" );Which is amazingly verbose. A lot of developers shorten this to: static Logger logger = Logger.getLogger( FeedLocator.class );But this still leaves us with cut and paste errors.What if we could just reduce it to: static Logger logger = Logger.g ...'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmXtXU9FXvJA"
      },
      "source": [
        "# Токенизация и финиш"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXyXCR4uXymw",
        "outputId": "2f46d02a-095d-45c4-c56c-cbe3160af417"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "from nltk.stem import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('wordnet')\n",
        "\n",
        "snowball_stemmer_obj = SnowballStemmer('english')\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "full_df = pd.concat([df_train, df_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nicizWEulovh",
        "outputId": "7bacd354-905f-441f-9eef-10826db6d4aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index of row on process 119999/119999\n",
            "Nets get Carter from Raptors.\n",
            "INDIANAPOLIS  All-Star Vince Carter was traded by the Toronto Raptors to the New Jersey Nets for Alonzo Mourning, Eric Williams, Aaron Williams, and a pair of first-round draft picks yesterday.\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "for index, row in df_train.iterrows():\n",
        "  clear_output()\n",
        "  print(f\"index of row on process {index}/119999\")\n",
        "  text = row['title'] + '. ' + row['text']\n",
        "  # 0) сплит по предложениям\n",
        "  sentences = re.split(sentence_split_regex, text)\n",
        "  with open(f\"gdrive/My Drive/Colab Notebooks/nlp-2023/assets/train/{row['class']}/{index}.tsv\", 'w') as writefile:\n",
        "    for sentence in sentences:\n",
        "      # 1) замены и выброс мусора\n",
        "      sentence = re.sub(dollar_code_sub_regex, '$', sentence)\n",
        "      sentence = re.sub(clear_sub_regex, '', sentence)\n",
        "      # 2) вычленение токенов\n",
        "      print(sentence)\n",
        "      tokens = re.findall(regex_to_take_tokens, sentence)\n",
        "      # 3) вычисление леммы, стеммы и запись\n",
        "      for token in tokens:\n",
        "        lemma = lemmatizer.lemmatize(token)\n",
        "        stemma = snowball_stemmer_obj.stem(token)\n",
        "        writefile.write(f\"{token}\\t{stemma}\\t{lemma}\\n\")\n",
        "      writefile.write('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YTDJCWHVBYsi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09ebfa8c-b2a9-4a14-b91c-411acffed745"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "index of row on process 7599/7599\n",
            "EBay gets into rentals. EBay plans to buy the apartment and home rental service Rent.com for \\$415 million, adding to its already exhaustive breadth of offerings.\n"
          ]
        }
      ],
      "source": [
        "row_num = 0\n",
        "\n",
        "for index, row in df_test.iterrows():\n",
        "  clear_output()\n",
        "  print(f\"index of row on process {index}/7599\")\n",
        "  row_num = row_num + 1\n",
        "  text = row['title'] + '. ' + row['text']\n",
        "  print(text)\n",
        "  # 0) сплит по предложениям\n",
        "  sentences = re.split(sentence_split_regex, text)\n",
        "  with open(f\"gdrive/My Drive/Colab Notebooks/nlp-2023/assets/test/{row['class']}/{index}.tsv\", 'w') as writefile:\n",
        "    for sentence in sentences:\n",
        "      # 1) замены и выброс мусора\n",
        "      sentence = re.sub(dollar_code_sub_regex, '$', sentence)\n",
        "      sentence = re.sub(clear_sub_regex, '', sentence)\n",
        "      # 2) вычленение токенов\n",
        "      tokens = re.findall(regex_to_take_tokens, sentence)\n",
        "      # 3) вычисление леммы, стеммы и запись\n",
        "      for token in tokens:\n",
        "        lemma = lemmatizer.lemmatize(token)\n",
        "        stemma = snowball_stemmer_obj.stem(token)\n",
        "        writefile.write(f\"{token}\\t{stemma}\\t{lemma}\\n\")\n",
        "      writefile.write('\\n')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}